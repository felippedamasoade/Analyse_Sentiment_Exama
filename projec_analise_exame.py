# -*- coding: utf-8 -*-
"""Projec_Analise_Exame.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1l36MMnvKaR47BOxu1HNX8F9I5Ips5sG2
"""

!pip install nltk

import pandas as pd
import nltk
nltk.download('all')

from nltk.sentiment.vader import SentimentIntensityAnalyzer

from nltk.corpus import stopwords

from nltk.tokenize import word_tokenize

from nltk.stem import WordNetLemmatizer

df = pd.read_csv('/content/artigos_exame.csv')
df

def preprocess_text(text):
  tokens = word_tokenize(text)
  tokens = word_tokenize(text.lower())
  filtered_tokens = [token for token in tokens if token not in stopwords.words('english')]
  lemmatizer = WordNetLemmatizer()
  lemmatized_tokens = [lemmatizer.lemmatize(token) for token in filtered_tokens]
  processed_text = ' '.join(lemmatized_tokens)

  return processed_text

df['reviewText'] = df['Conteúdo'].apply(preprocess_text)
df

analyzer = SentimentIntensityAnalyzer()

def get_sentiment(text):
    scores = analyzer.polarity_scores(text)

    # Define thresholds for classification
    if scores['compound'] >= 0.05:
        sentiment = "good"  # Positive sentiment
    elif scores['compound'] <= 0.05:
        sentiment = "bad"  # Negative sentiment
    else:
        sentiment = "neutral"  # Neutral sentiment

    return sentiment

df['sentiment'] = df['Conteúdo'].apply(get_sentiment)

df

df[df['sentiment'] == 1 ]

sentiment_fraction = df['sentiment'].value_counts(normalize=True)
sentiment_fraction

fractions = df['sentiment'].value_counts(normalize=True)

df['frac'] = df['sentiment'].map(fractions)

df

